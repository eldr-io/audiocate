# audiocate

![Haskell](https://img.shields.io/badge/Haskell-5e5086?style=for-the-badge&logo=haskell&logoColor=white) [![Haskell CI](https://github.com/eldr-io/audiocate/actions/workflows/haskell.yml/badge.svg)](https://github.com/eldr-io/audiocate/actions/workflows/haskell.yml) ![Code Coverage](https://img.shields.io/badge/Code%20Coverage%20-%2094%25%20-%2094%25)


Audio encoding authentication library for verifying audio as being from a trusted source.

### Description

The purpose of audiocate is to embed meaningful payloads into audio that will allow a decoder to
verify that the payload came from a trusted source. The primary motivation is to combat the rising misuse of audio deepfakes generated by modern Artificial Intelligence (AI). 
For this, it makes use of the TOTP (Time-based One Time Password) algorithm to
introduce a time-horizon into the algorithm. This concept is at the heart of audiocate, which in the
encoding stage repeatedly encodes binary data into chunks of audio input. The binary data consists of
two parts, one representing the timestamp of the current system time (in the form of an unsigned 64-bit
integer representing POSIX seconds since an epoch), followed by the result of calculating the TOTP value
using the current time alongside a secret key and validity time window. In the decoding stage, the
algorithm repeatedly reads the binary representation of an encoded timestamp and result code, and
then calculates its own result code using a secret key and validity time window before assessing if the
chunk of audio was successfully decoded by comparing the two result codes.

Audiocate currently uses Least Significant Bit (LSB) encoding, but its modular nature allows for future support for Echo Hiding. The imperceptibility of audiocate is high as it encodes very minimal payloads into audio, as shown in the comparison spectrogram showing the difference between a raw audio and the audiocate encoded spectrogram:

![spectroDiff](https://github.com/eldr-io/audiocate/assets/83576392/917af028-e869-4439-b3bd-b6d2e2b5c182)

#### Example use-case
A mobile phone carrier may want to implement audiocate using its composable real-time streaming
functionality, so that audiocate sits on either side of the call, encoding chunks on one end and
decoding them on the other:

![cellNoText](https://github.com/eldr-io/audiocate/assets/83576392/daa5e686-e2a3-4a3e-97c8-9b3128a2aa5c)

### Executables

Audiocate is a library at its core, but exposes a CLI and a simple GUI (written using GTK) for interaction with the library.

![gui](https://github.com/eldr-io/audiocate/assets/83576392/17b4a6e2-8293-4298-8efd-7d28155848a1)

### How to
#### Build all
Builds all of the audiocate artifacts for the current operating system.
```
make build-all
```
#### Generate docs
Generates the haddock documentation for the audiocate-library and places it in `/docs`.
```
make generate-docs
```

#### Run tests
Builds and runs all of the unit and integration tests of the project. The `test/corpus/` directory holds fourteen sample .WAVE files used for testing, which represent different audio samples of real recordings and AI generated deepfakes.
```
make run-test
```

#### Run benchmarks
Note: this is a long-running process. Use the pattern benchmark target below to target specific sample files for benchmarking.
```
make benchmark-test
```
Run benchmarks with pattern:
```
make pattern=stream benchmark-pattern
```
#### Analyse spectrograms
After having run the integration tests, this target generates spectrogram images for each of the sample files and compares it to the original.
```
make analyse-spectograms
```
